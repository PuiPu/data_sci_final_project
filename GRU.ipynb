{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PuiPu/data_sci_final_project/blob/main/GRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the uploaded CSV file to check its structure\n",
        "file_path = '/mnt/data/aapl_us_d.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows of the data\n",
        "data.head()\n"
      ],
      "metadata": {
        "id": "KuQ7DWxjeZBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Convert Date to datetime format and set as index\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "data.set_index('Date', inplace=True)\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = data.isnull().sum()\n",
        "\n",
        "# Use only the 'Close' column for this task\n",
        "close_prices = data['Close']\n",
        "\n",
        "# Display basic information about the data\n",
        "missing_values, close_prices.describe()\n"
      ],
      "metadata": {
        "id": "MvCxAIoCedq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "close_prices_scaled = scaler.fit_transform(close_prices.values.reshape(-1, 1))\n",
        "\n",
        "# Define a function to create sequences for time series prediction\n",
        "def create_sequences(data, seq_length):\n",
        "    sequences = []\n",
        "    targets = []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        sequences.append(data[i:i + seq_length])\n",
        "        targets.append(data[i + seq_length])\n",
        "    return np.array(sequences), np.array(targets)\n",
        "\n",
        "# Define sequence length\n",
        "sequence_length = 60  # Use 60 days of data to predict the next day's price\n",
        "\n",
        "# Create sequences\n",
        "X, y = create_sequences(close_prices_scaled, sequence_length)\n",
        "\n",
        "# Split into training and testing datasets\n",
        "train_size = int(len(X) * 0.8)  # 80% training data\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "# Display the shapes of the datasets\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
      ],
      "metadata": {
        "id": "u1xDiWcReh6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
        "\n",
        "# Define the GRU model\n",
        "model = Sequential([\n",
        "    GRU(50, return_sequences=True, input_shape=(sequence_length, 1)),  # First GRU layer\n",
        "    Dropout(0.2),  # Dropout for regularization\n",
        "    GRU(50),  # Second GRU layer\n",
        "    Dropout(0.2),\n",
        "    Dense(1)  # Output layer to predict the next price\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, y_test),\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "_7a3DGD2eirf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "歡迎使用 Colaboratory",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}